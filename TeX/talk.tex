\documentclass[ucs, notheorems, handout]{beamer}

\usetheme[numbers,totalnumbers,compress, nologo]{Statmod}
\usefonttheme[onlymath]{serif}
\setbeamertemplate{navigation symbols}{}

\mode<handout> {
    \usepackage{pgfpages}
    \setbeameroption{show notes}
    \pgfpagesuselayout{2 on 1}[a4paper, border shrink=5mm]
    \setbeamercolor{note page}{bg=white}
    \setbeamercolor{note title}{bg=gray!10}
    \setbeamercolor{note date}{fg=gray!10}
}

\usepackage[utf8x]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{tikz}
\usepackage{ragged2e}
\usepackage{t-angles}
\usepackage{slashbox}
\include{letters_series_mathbb}

\setbeamercolor{bluetext_color}{fg=blue}
\newcommand{\bluetext}[1]{{\usebeamercolor[fg]{bluetext_color}#1}}

\newtheorem{theorem}{Теорема}
\newtheorem{statement}{Утверждение}

\title[Tensor SSA]{Тензорный анализ сингулярного спектра}

\author{Хромов Никита Андреевич, гр.20.Б04-мм}

\institute[Санкт-Петербургский Государственный Университет]{%
    \small
    Санкт-Петербургский государственный университет\\
    Прикладная математика и информатика\\
    Вычислительная стохастика и статистические модели\\
    \vspace{1.25cm}
    Отчет по производственной практике (научно-исследовательская работа) (6 семестр)}

\date[Зачёт]{Санкт-Петербург, 2023}

\subject{Talks}

\begin{document}

    \begin{frame}[plain]
        \titlepage

        \note{Научный руководитель к.ф.-м.н., доцент Голяндина Н.Э.,\\
        кафедра статистического моделирования}
    \end{frame}


%\section{Короткая тема}
%\subsection{Общие слова}

%    \setbeameroption{show notes}


    \section{Введение}\label{sec:intro}
    \begin{frame}{Введение}
        Временной ряд длины $N$: $\tX=(x_1, x_2,\ldots, x_N)$.

        $\tX = \tT + \tP + \tR$.
        \vspace{0.8cm}

        \bluetext{Возможные задачи:}
        \begin{enumerate}
            \item Выделение сигнала из ряда: нахождение $\tT + \tP$;
            \item Отделение компонент сигнала: нахождение $\tT$ и $\tP$.
        \end{enumerate}

        \vspace{0.8cm}
        Одним из методов решения этих задач является метод Singular Spectrum Analysis
        (\bluetext{SSA}) Golyandina et al. (2001), Analysis of time series structure: SSA and related techiques.
        \note{
            Временным рядом длины $N$ называется последовательность $N$ чисел.
            В общем случае, временной ряд является суммой трёх компонент: тренда $\tT$, сезонности $\tP$ и
            шума $\tR$.

            Можно рассматривать задачи анализа временного ряда:
            \begin{enumerate}
                \item Выделение сигнала $\tT+\tP$ из ряда;
                \item Отделение компонент сигнала $\tT$ и $\tP$.
            \end{enumerate}
            Одним из методов решения этих задач является метод Singular Spectrum Analysis (SSA).
        }
    \end{frame}
    \begin{frame}{Введение}
        \begin{table}
            \begin{tabular}{lllll}
                \bluetext{SSA:} & ряд $\tX \Rightarrow$ & матрица $\mathbf{X} $ & $\Rightarrow$ & SVD $\mathbf{X}$  , \\
                \bluetext{Tensor SSA:} & ряд $\tX \Rightarrow$ & тензор $\mathcal{X} $ & $\Rightarrow$ & \begin{tabular}{l}
                                                                                                             тензорное\\ разложение
                \end{tabular} $\mathcal{X}$.
            \end{tabular}
        \end{table}

        \begin{itemize}
            \item Примеры тензорных разложений:
            \begin{enumerate}
                \item High-order singular value decomposition (\bluetext{HOSVD});
                \item Canonical polyadic decomposition (CPD).
            \end{enumerate}
            \item Для выделения сигнала и оценки его параметров в работе Papy et al. (2005) применялось HOSVD, и
            в работе De~Lathauwer et al. (2011) применялось CPD.
        \end{itemize}
        \item \bluetext{Задача:} изучить различные варианты тензорных разложений, применить их
        в задаче анализа временного ряда и сравнить результаты с SSA\@.

        Из тензорных разложений первым было выбрано HOSVD, так как оно имеет наибольшее сходство с SVD\@.

        \note{
            \footnotesize
            В методе SSA происходит построение особой матрицы по ряду и применение к ней сингулярного разложения.

            Возможное обобщение этого метода --- переход от матриц к тензорам: построение
            по ряду особого тензора и применение к нему некоторого тензорного разложения.

            Существует множество видов тензорных разложений.
            Для нас интерес представляют High-Order Singular Value Decomposition (HOSVD), являющееся
            многомерным аналогом SVD, и Canonical Polyadic Decomposition (CPD).

            Оба этих разложения были использованы в разных работах для выделения из ряда сигнала и его оценки:
            HOSVD --- в работе~\cite{tssa-hosvd}, и CPD --- в работе~\cite{tssa-cpd}.

            Была поставлена задача изучить выбранные варианты тензорных разложений, реализовать метод Tensor SSA,
            и сравнить с методом Basic SSA по точности выделения сигнала и компонент сигнала.

            Из тензорных разложений первым было выбрано HOSVD, так как оно имеет наибольшее сходство с SVD\@.
        }
    \end{frame}


    \section{Известные результаты и определения}\label{sec:known}
    \begin{frame}{Описание HOSDV}
        Пусть имеется тензор $\mathcal{A}\in \mathbb{C}^{I_1\times I_2 \times \ldots \times I_M}$, тогда HOSVD $\mathcal{A}$:

        \item \begin{equation*}
                  \mathcal{A}=\sum_{i_1=1}^{I_1} \sum_{i_2=1}^{I_2}\ldots \sum_{i_M=1}^{I_M} \mathcal{Z}_{i_1,i_2,\ldots,i_M}
                  U^{(1)}_{i_1} \circ U^{(2)}_{i_2} \circ \ldots\circ U^{(M)}_{i_M},
        \end{equation*}
        где
        \begin{itemize}
            \item $\mathbf{U}^{(n)}=\left[U^{(n)}_{1}, \ldots, U^{(n)}_{I_n}\right]$ --- унитарные матрицы;
            \smallskip
            \item Тензор $\mathcal{Z}\in\mathbb{C}^{I_1\times I_2 \times \ldots \times I_M}$ удовлетворяет свойствам
            \begin{enumerate}
                \item полная ортогональность:
                \[
                    \langle\mathcal Z_{i_n=\alpha},\mathcal Z_{i_n=\beta}\rangle=0 \qquad \alpha\ne\beta,
                \]
                \item упорядоченность:
                \begin{equation*}
                    \|\mathcal Z_{i_n=1}\|\geqslant\|\mathcal Z_{i_n=2}\| \geqslant \ldots \geqslant\|\mathcal Z_{i_n=I_n}\|.
                \end{equation*}
            \end{enumerate}
        \end{itemize}

        \note{
            Любой комплекснозначный тензор $\mathcal{A}$ размерности $I_1\times I_2 \times \ldots \times I_M$, может быть представлен
            в виде суммы тензоров ранга $1$, то есть внешних произведений векторов, как показано на слайде.
            $M$ называется количеством измерений тензора.
            Такое представление называется HOSVD тензора $\mathcal{A}$, векторы $U_i^{(n)}$ называют
            $i$-м сингулярным вектором тензора $\mathcal A$ по измерению $n$, нормы Фробениуса подтензора $\mathcal{Z}$ с
            фиксированным $n$-м индексом равным $i$ называют $i$-м сингулярным значением тензора $\mathcal{A}$
            по измерению $n$.

            Свойство полной ортогональности является аналогом свойства диагональности матрицы сингулярных значений в SVD,
            а свойство упорядоченности собственных значений вдоль каждого измерения --- аналог упорядоченности собственных значений.
        }
    \end{frame}

    \begin{frame}{Свойства HOSVD}
        Все свойства представлены в работе De Lathauwer et al. (2000).
        \begin{itemize}
            \item HOSVD --- единственное $M$-ортогональное разложение.
            \vspace{0.3cm}
            \item При $M=2$ HOSVD совпадает с SVD\@.
            \vspace{0.3cm}
            \item Пусть $\operatorname{rank}_n(\mathcal{A})$ --- размерность
            пространства векторов измерения $n$ тензора.
            Если в HOSVD тензора $\mathcal{A}$ $r_n$ --- наибольший индекс такой, что $\|\mathcal{Z}_{i_n=r_n}\|>0$,
            то $r_n=\operatorname{rank}_n(\mathcal{A})$.
            \vspace{0.3cm}
            \item
            \begin{gather*}
                \|\mathcal{A}\|^2=\sum_{i=1}^{R_1}\left( \sigma_i^{(1)} \right)^2=\sum_{i=1}^{R_2}\left( \sigma_i^{(2)} \right)^2
                =\ldots =\sum_{i=1}^{R_M}\left( \sigma_i^{(M)} \right)^2= \|\mathcal{Z}\|^2\\
                \sigma_{i}^{(n)}=\|\mathcal{Z}_{{i_n}=i}\|, \qquad R_n=\operatorname{rank}_n(\mathcal{A}).
            \end{gather*}
        \end{itemize}
        \note{
        \footnotesize
            \begin{enumerate}
                \item HOSVD является единственным $M$-ортогональным разложением тензора, и сингулярные значения и векторы
                определяются с точностью до унитарных преобразований.
                \item Результат применения HOSVD к тензору с двумя измерениями, т.е. матрице, совпадает
                с результатом применения SVD к этой же матрице, в точности до унитарных преобразований сингулярных векторов и
                матрицы сингулярных значений.
                \item $n$-рангом тензора $\mathcal{A}$ называется размерность векторного пространства, порождённого
                векторами измерения $n$ этого тензора.
                Обозначается $R_n=\operatorname{rank}_{n}(\mathcal{A})$.
                Если в HOSVD тензора $\mathcal{A}$ $r_n$ --- наибольший индекс такой, что $\|\mathcal{Z}_{i_n=r_n}\|>0$,
                то $r_n=\operatorname{rank}_n(\mathcal{A})$;
                $n$-ранги являются характеристикой тензора, аналогичной матричным рангам.
                Однако в тензорном случае, $n$-ранги могут различаться, поэтому для каждого измерения определяется своя характеристика.
                \item Квадрат нормы тензора совпадает с суммами квадратов сингулярных значений по каждому из измерений и совпадает
                с квадратом нормы тензора $\mathcal{Z}$ из разложения.
            \end{enumerate}
        }
    \end{frame}

    \begin{frame}{Свойства HOSVD}
        \begin{itemize}
            \item Векторы тензора $\mathcal{A}$ по измерению $n$ в основном содержат вклады в направлении $U^{(n)}_1$,
            величина этого вклада равна $\sigma^{(n)^2}_1$.
            Следующий по величине вклад по измерению $n$ достигается в направлении $U^{(n)}_2$,
            перпендикулярном $U^{(n)}_1$, с величиной $\sigma^{(n)^2}_2$, и т.д.
            \vspace{0.4cm}
            \item Определим тензор $\hat{\mathcal{A}}$ отбрасыванием наименьших сингулярных значений $\sigma_{I_{n}'+1}^{(n)},
            \sigma_{I_{n}'+2}^{(n)},\ldots, \sigma_{R_n}^{(n)}$, тогда
            \begin{equation*}
                \|\mathcal{A}-\hat{\mathcal{A}}\|^2\leqslant \sum_{i_1=I_{1}'+1}^{R_1}\left( \sigma_{i_1}^{(1)}\right)^2 +
                \ldots + \sum_{i_M=I_{M}'+1}^{R_M}\left( \sigma_{i_M}^{(M)}\right)^2.
            \end{equation*}
        \end{itemize}
        \note{
            \scriptsize
            \begin{enumerate}
                \item Векторы тензора $\mathcal{A}$ по измерению $n$ в основном содержат вклады в направлении $U^{(n)}_1$,
                и вклад в этом направлении равен $\sigma^{(n)^2}_1$.
                Следующий по величине вклад по измерению $n$ достигается в направлении $U^{(n)}_2$,
                перпендикулярном $U{(n)}_1$, с величиной $\sigma^{(n)^2}_2$, и так далее.
                \item Пусть $R_n=\operatorname{rank}_n(\mathcal{A})$.
                Определим тензор $\hat{\mathcal{A}}$ отбрасыванием наименьших сингулярных значений $\sigma_{I_{n}'+1}^{(n)}, \sigma_{I_{n}'+2}^{(n)},\ldots, \sigma_{R_n}^{(n)}$
                для заданных значений $I_{n}'$, $n \in \overline{1:M}$, то есть заменяя нулями соответствующие части тензора $\mathcal{Z}$.
                Тогда квадрат нормы разности тензоров не превосходит суммы квадратов отброшенных сингулярных значений.
            \end{enumerate}
            Эти свойства являются эквивалентом высшего порядка связи между SVD матрицы и ее наилучшим приближением,
            в смысле наименьших квадратов, матрицей более низкого ранга.
            Однако для тензоров ситуация совершенно иная.
            Тензор, полученный усечением HOSVD в общем случае не является наилучшим приближением при заданных
            ограничениях на ранги измерений, но это приближение всё же можно считать достаточно точным.
        }
    \end{frame}


    \section{Описание HOSVD SSA и его свойства}\label{sec:tssa-intro}
    \begin{frame}{Описание метода HOSVD SSA}
        Имеется временной ряд $\tX=(x_1, x_2,\ldots, x_N)$.
        Приведём формулировки алгоритма HOSVD SSA для решения различных задач.\\
        \bluetext{Входные данные алгоритма}: $I,L: 1\leqslant I,L \leqslant N,\, I + L \leqslant N + 1$.\\
        \bluetext{Траекторный тензор:} тензор размерности $I\times L\times J=N-I-J+2$, строится по ряду:
        \[
            \mathcal{X}_{i,l,j}=x_{i+l+j-2}\qquad i\in \overline{1:I},\, l \in\overline{1:L},\, j \in\overline{1:J}.
        \]
        Слои траекторного тензора:
        \[
            \mathcal{X}_{,,j}=
            \begin{pmatrix}
                x_j       & x_{j+1} & \ldots & x_{j+L-1}   \\
                x_{j+1}   & x_{j+2} &        & \vdots      \\
                \vdots    &         & \ddots & \vdots      \\
                x_{j+I-1} & \ldots  & \ldots & x_{j+I+L-2}
            \end{pmatrix}.
        \]

        \note{
            Пусть имеется временной ряд $\tX=(x_1, x_2,\ldots, x_N)$. Приведём формулировки алгоритма HOSVD SSA для решения различных задач.
            Входные данные алгоритма: два числа $I,L: 1\leqslant I,L \leqslant N,\, I + L \leqslant N + 1$.

            Введём понятие траекторного тензора: это тензор, составленный из элементов ряда таким образом,
            что его $i,l,j$-й элемент равен $i+l+j-2$-му элементу ряда.
            На слайде представлен слой траекторного тензора, полученный фиксированием третьего
            измерения индексом $j$.
            Похожим образом выглядят и остальные слои.
        }
    \end{frame}

    \begin{frame}{HOSVD SSA: отделение компонент сигнала}
        \bluetext{Задача:} отделение компонент сигнала в ряде.
        \vspace{0.6cm}
        \begin{enumerate}
            \item \bluetext{Вложение:} выбор параметров $I, L$ и построение по ним траекторного тензора $\mathcal{X}$;
            \vspace{0.4cm}
            \item \bluetext{Разложение:} Проведение HOSVD траекторного тензора $\mathcal{X}$, получение его представления в виде
            \begin{equation*}
                \mathcal{X}=\sum_{i=1}^{I} \sum_{l=1}^{L} \sum_{j=1}^{J} \mathcal{Z}_{i,l,j} \mathbf{U}^{(1)}_{i}
                \circ \mathbf{U}^{(2)}_{l} \circ \mathbf{U}^{(3)}_{j};
            \end{equation*}
        \end{enumerate}
        \note{
            Рассмотрим задачу отделения компонент сигнала в ряде.
            \begin{enumerate}
                \item Первый шаг алгоритма заключается в выборе параметров $I, L$ и построение по ним траекторного тензора ряда.
                \item Второй шаг алгоритма заключается в проведении разложения HOSVD траекторного тензора.
                В результате получается представление в виде суммы тензоров ранга $1$ (то есть внешних произведений векторов).
            \end{enumerate}
        }
    \end{frame}

    \begin{frame}{HOSVD SSA: отделение компонент сигнала}
        \begin{enumerate}
            \setcounter{enumi}{2}
            \item \bluetext{Группировка:} разбиение множества индексов $\mathfrak{S}=\{1,\, 2\,\ldots,\, \min(I, L, J)\}$ по смыслу на
            непересекающиеся множества $\mathfrak{S}_k,\, k\in\overline{1:m}$ и построение по этому разбиению тензоров
            \[
                \mathcal{X}^{(\mathfrak{S}_k)}=\sum_{i \in \mathfrak{S}_k} \sum_{l\in \mathfrak{S}_k} \sum_{j\in \mathfrak{S}_k}
                \mathcal{Z}_{i,l,j} \mathbf{U}^{(1)}_{i}\circ \mathbf{U}^{(2)}_{l} \circ \mathbf{U}^{(3)}_{j}.
            \]
            \vspace{0.2cm}
            \item \bluetext{Восстановление:} получение рядов $\tX^{(k)}=\tX^{(\mathfrak{S}_k)}$ по тензорам
            $\mathcal{X}^{(\mathfrak{S}_k)}$ посредством их усреднения вдоль плоскостей $i+l+j=\operatorname{const}.$
        \end{enumerate}
        \vspace{0.2cm}
        \bluetext{Результат алгоритма:} набор рядов $\tX^{(k)}$ таких, что
        \[
            \tX=\sum_{k=1}^{m}\tX^{(k)}.
        \]
        \note{
            \begin{enumerate}
                \item Третий шаг: группировка.
                На этом шаге множество индексов суммирования разбивается на непересекающиеся
                множества по смыслу, и по этим множествам определяется набор тензоров, соответствующих различным
                компонентам сигнала.
                \item Четвёртый шаг: восстановление.
                На этом шаге полученные после группировки тензоры усредняются
                вдоль плоскостей с фиксированным значением суммы индексов.
            \end{enumerate}
            В результате усреднения получается набор временных рядов, в сумме дающий исходный ряд, этот
            набор и будет результатом алгоритма.
        }
    \end{frame}

    \begin{frame}{HOSVD SSA: отделение сигнала усечением HOSVD}
        \bluetext{Задача:} выделение сигнала из ряда.

        \vspace{0.4cm}
        Способы реализации HOSVD SSA для решения этой задачи: \bluetext{усечение HOSVD} и High-order orthogonal iteration
        (\bluetext{HOOI}).
        Начнём с усечения HOSVD\@.

        \vspace{0.2cm}
        Первые два шага в этом алгоритме --- вложение и разложение, были описаны выше.

        \begin{enumerate}
            \setcounter{enumi}{2}
            \item \bluetext{Усечение:} выбор ранга сигнала $r$ и обнуление матриц-слоёв тензора $\mathcal{Z}$ с номерами $k>r$
            по каждому измерению.
            Построение по этому усечению тензора $\hat{\mathcal{X}}$.
            \item \bluetext{Восстановление:} усреднение тензора $\hat{\mathcal{X}}$ вдоль плоскостей $i+l+j=\operatorname{const}$.
        \end{enumerate}

        \vspace{0.2cm}
        \bluetext{Результат алгоритма:} полученный усреднением ряд $\hat{\tX}$ будем считать сигналом.
        \note{
            \footnotesize
            Рассмотрим задачу выделения сигнала из ряда.
            Алгоритм HOSVD SSA для решения этой задачи может быть проведён двумя различными способами:
            используя усечение HOSVD и используя High-order orthogonal iteration (о втором будет сказано позже).

            Первый способ заключается в усечении сингулярного разложения траекторного тензора.
            Первые два шага этого алгоритма совпадают с алгоритмом для отделения компонент ряда, поэтому опишем его, начиная с третьего шага.
            \begin{enumerate}
                \setcounter{enumi}{2}
                \item Третий шаг заключается в выборе ранга сигнала $r$ и усечении тензора сингулярных значений по этому рангу.
                Другими словами, имея ранг сигнала $r$ и разложение траекторного тензора $\mathcal{X}$,
                в тензоре $\mathcal{Z}$ заменим матрицы-слои по каждому измерению с номерами $k>r$ на нулевые, и по полученному тензору
                построим приближение траекторного тензора $\hat{\mathcal{X}}$.
                \item На четвёртом шаге, используя усреднение тензора $\hat{\mathcal{X}}$ вдоль плоскостей $i+l+j=\operatorname{const}$
                получим ряд $\hat{\tX}$.
                Этот ряд и будем считать сигналом.
            \end{enumerate}
            Стоит отметить, что этот способ не является оптимальным.
        }
    \end{frame}

    \begin{frame}{HOSVD SSA: отделение сигнала с помощью HOOI}
        \bluetext{Задача:} выделение сигнала из ряда.

        \vspace{0.4cm}
        Второй способ использует HOOI --- метод приближения тензора другим тензором с меньшими значениями $n$-рангов.
        В отличие от усечения, этот метод является оптимальным.

        \vspace{0.2cm}
        Первый шаг алгоритма --- вложение, совпадает с предыдущими алгоритмами, поэтому опишем его начиная со второго шага.
        \begin{enumerate}
            \setcounter{enumi}{1}
            \item \bluetext{HOOI:} Выбор ранга сигнала $r$ и применение к $\mathcal{X}$
            HOOI с набором $n$-рангов $(r,\, r,\, r)$.
            Результат --- оптимальное приближение тензором $\hat{\mathcal{X}}$ с
            $n$-рангами $r$.
            \item \bluetext{Восстановление:} усреднение тензора $\hat{\mathcal{X}}$ аналогично восстановлению в варианте
            с усечением.
        \end{enumerate}

        \vspace{0.2cm}
        \bluetext{Результат алгоритма:} полученный усреднением ряд $\hat{\tX}$ будем считать сигналом.
        \note{
            \scriptsize
            Второй способ использует метод приближения тензора другим тензором с меньшими значениями $n$-рангов --- High-Order Orthogonal
            Iteration (HOOI)~\cite{hooi}.
            В отличие от усечения, этот метод является оптимальным, в том смысле, что на тензоре, полученном
            этим методом достигается минимум расстояния, в смысле нормы Фробениуса, до исходного тензора
            по всем тензорам с данными ограничениями на ранги.

            Приведём вторую реализацию алгоритма HOSVD SSA для отделения сигнала от шума, используя HOOI\@.
            Первый шаг алгоритма --- вложение, совпадает с предыдущими алгоритмами, поэтому
            опишем его начиная со второго шага.
            \begin{enumerate}
                \setcounter{enumi}{1}
                \item На втором шаге выбирается ранг сигнала $r$ и к полученному ранее траекторному тензору $\mathcal{X}$ применяется
                HOOI с набором $n$-рангов $(r,\, r,\, r)$.
                В результате получаем оптимальное приближение траекторного тензора $\mathcal{X}$ тензором $\hat{\mathcal{X}}$ со
                значениями $n$-рангов равными $r$.
                \item Третий шаг --- восстановление ряда по тензору $\hat{\mathcal{X}}$ усреднением совпадает с
                четвёртым шагом (восстановлением) в первом варианте алгоритма для выделения сигнала из ряда.
            \end{enumerate}
            Полученный усреднением ряд $\hat{\tX}$ будем считать сигналом.
        }
    \end{frame}

    \begin{frame}{Свойства HOSVD SSA, разделимость рядов}
        \bluetext{Разделимость} и \bluetext{ранг} рядов являются важными понятиями в теории SSA.
        Рассмторим эти понятия для алгоритма HOSVD SSA

        \vspace{0.5cm}
        \begin{enumerate}
            \item \bluetext{Разделимость рядов}
            \begin{statement}
                Если временные ряды $\tilde{\tX}$ и $\hat{\tX}$ длины $N$ слабо $I$- и
                $L$-разделимы в смысле теории \emph{SSA}, то существует такое \emph{HOSVD} траекторного тензора $\mathcal{X}$ ряда
                $\tX=\tilde{\tX} + \hat{\tX}$, что его можно в виде суммы \emph{HOSVD} траекторных тензоров рядов
                $\tilde{\tX}$ и $\hat{\tX}$.
            \end{statement}
        \end{enumerate}

        \vspace{0.6cm}
        Понятие слабой разделимости рядов из SSA применимо к тензорному случаю
        \note{
            Метод SSA хорошо изучен и важную роль в теории играют понятия разделимости и ранга рядов.
            Рассмторим эти понятия для алгоритма HOSVD SSA.

            Первое утверждение о разделимости позволяет перенести понятие слабой разделимости
            рядов из теории SSA на тензорный случай.

            Само утверждение заключается в том, что если временные ряды $\tilde{\tX}$ и $\hat{\tX}$ длины $N$ слабо $I$- и
            $L$-разделимы в смысле теории SSA, то существует такое сингулярное разложение траекторного тензора $\mathcal{X}$ ряда
            $\tX=\tilde{\tX} + \hat{\tX}$, что его можно в виде суммы сингулярных разложений траекторных тензоров,
            составленных по рядам $\tilde{\tX}$ и $\hat{\tX}$.

            Доказательство утверждения следует из ортогональности сингулярных векторов в HOSVD.
        }
    \end{frame}

    \begin{frame}{Свойства HOSVD SSA, ранг ряда}
        \begin{enumerate}
            \setcounter{enumi}{1}
            \item \bluetext{Ранг ряда}
            \begin{statement}
                Пусть временной ряд $\tX$ имеет конечный ранг $d$ в терминах \emph{SSA}\@.
                Тогда для любых значений параметров $I$ и $L$ таких, что
                \[
                    d\leqslant\min(I, L, N-I-L+2),
                \]
                количество ненулевых сингулярных чисел по каждому измерению в \emph{HOSVD} траекторного тензора $\mathcal{X}$
                этого ряда с параметрами $I$ и $L$ будет равно $d$.
            \end{statement}
        \end{enumerate}

        \vspace{0.4cm}
        Понятие ранга ряда имеет тот же смысл в терминах HOSVD SSA, что и в стандартной теории SSA, причём ряды конечного ранга
        имеют одинаковые ранги в тензорном и стандартном случаях.

        \note{
            Второе утверждение о ранге ряда говорит о том, что понятие ранга ряда имеет тот же смысл в терминах HOSVD SSA,
            что и в стандартной теории SSA, причём ряды конечного ранга имеют одинаковые ранги в тензорном и стандартном случаях.

            Само утверждение звучит заключается в том, что если ряд имеет конечный ранг $d$, то для любых допустимых
            параметров $I, L$ количество ненулевых сингулярных чисел по каждому измерению в сингулярном разложении траекторного тензора
            $\mathcal{X}$ будет равно $d$.

            Доказательство этого утверждения следует из свойств $n$-рангов сингулярного разложения.
        }
    \end{frame}


    \section{Применение HOSVD SSA}\label{sec:tssa-use}
    \begin{frame}{Примеры слабой разделимости}
        \begin{itemize}
            \item Экспонента и косинус с экспоненциально-модулированной амплитудой: $\tilde{x}_n=e^{-\alpha n}\cos(2\pi n / T + \varphi),\, \hat{x}_n=e^{\alpha n}$, $n \in \overline{1:N}$.

            Если $(N+2)\: \vdots \: T$, то при выборе $I,\, L:\: I+L< N+1$, делящихся нацело на $T$ $\tilde{\tX}$ и $\hat{\tX}$
            слабо разделимы.

            \item Два косинуса: $\tilde{x}_n=\cos(2\pi \omega n + \varphi),\, \hat{x}_n=\cos(2\pi \omega' n + \varphi')$, $0 < \omega < 1/2$.
            тогда ряд $\tilde{\tX}$ отделим от ряда $\hat{\tX}$ в смысле Tensor SSA тогда и только тогда, когда
            $\tilde{\tX}$ и $\hat{\tX}$ слабо разделимы тогда и только тогда, когда $\omega\ne\omega'$, $I, L, J > 2$ и $I\omega,\,
            I\omega',\, L\omega,\, L\omega',\, J\omega,\, J\omega'$ --- целые числа.
        \end{itemize}

        \vspace{0.3cm}
        В последнем примере при одинаковых амплитудах происходит смешение компонент и в теории SSA говорят,
        что наблюдается приближённая разделимость.

        Как формализовать приближённую и точную разделимость в теории HOSVD SSA пока неясно.

        \note{
            Рассмотрим примеры слабо разделимых в терминах HOSVD SSA рядов.
            \begin{enumerate}
                \item Ряд косинуса с экспоненциально-модулированной амплитудой слабо отделим от ряда экспоненты той же степени, если $N+2$
                делится нацело на период косинуса и выбранные параметры делятся нацело на период.
                \item Ряды, порождённые косинусами с разными частотами слабо отделимы, если все измерения
                траекторного тензора имеют размерность больше 2, и делятся нацело на периоды обоих косинусов.
            \end{enumerate}
            В последнем примере при одинаковых амплитудах происходит смешение компонент.

            В SSA эта ситуация формализована, в HOSVD SSA пока неясно как можно формализовать приближённую и
            точную разделимость.
        }
    \end{frame}

    \begin{frame}{Сравнение HOSVD SSA и Basic SSA}
        \begin{itemize}
            \item $x_n = 2e^{0.035n}$, шум --- белый гауссовский, $\sigma^2=2.25$;
            \vspace{0.3cm}
            \item $x_n = 2 + 0.1n$, шум --- белый гауссовский, $\sigma^2_1=2.25,$, $\sigma^2_2=0.04$;
            \vspace{0.3cm}
            \item $x_n = 30\cos(2\pi n/12)$, шум --- белый гауссовский, $\sigma^2=25$, и красный, $\delta=\sqrt{5},\,
            \varphi_1=0.5, \varphi_2 = 0.9$.
        \end{itemize}

        Оценка точности --- RMSE по 500 реализациям шума: $\tX$ --- ряд длины $N$, $\tS_i$ --- выделенный
        в $i$-м эксперименте сигнал, тогда
        \begin{gather*}
        \widehat{\operatorname{RMSE}}(m)=\sqrt{\frac{1}{m} \sum_{i=1}^{m} \widehat{\operatorname{MSE}}(\tS_i, \tX)},\qquad
        \widehat{\operatorname{MSE}}(\tS, \tX)=\frac 1 N \sum_{k=1}^{N} (s_i-x_i)^2.
        \end{gather*}

        Во всех этих случаях метод SSA показал точность отделения сигнала выше, чем HOSVD SSA\@.
        \note{
            Были проведены численные измерения точности восстановления сигнала при использовании SSA и
            предложенных методов HOSVD SSA на примерах трёх рядов: порождённого экспонентой, линейного и косинуса.

            На экспоненциальный ряд действовали белым шумом и восстанавливали по одной компоненте.

            Для линейного ряда рассматривались ситуации большого и малого шума и в обеих ситуациях сравнивалось
            восстановление по одной и двум компонентам.

            На ряд косинуса действовали белым шумом и красным с разными параметрами.

            Шло сравнение точности метода SSA и методов HOSVD SSA с использованием усечения и HOOI.
            Во всех приведённых выше случаях метод SSA оказался точнее остальных.

            Оценка точности бралась равной корню из среднего значения среднеквадратичного отклонения восстановленного
            ряда от исходного по 500 реализациям шума.
        }
    \end{frame}
    \begin{frame}{Сравнение HOSVD SSA и Basic SSA}
        \footnotesize
        \begin{table}[ht]
            \centering
            \caption{RMSE восстановленного с помощью SSA сигнала, порождённого косинусом. $N=71$}
            \begin{tabular}{r|rrrr}
                \hline
                \backslashbox{вид шума}{$L$} & 12   & 24   & 30            & 36   \\
                \hline
                белый, $\sigma^2=25$         & 1.82 & 1.42 & \textbf{1.40} & 1.42 \\\hline
                красный, $\varphi=0.5$       & 1.31 & 1.03 & \textbf{1.01} & 1.03 \\\hline
                красный, $\varphi=0.9$       & 1.88 & 1.37 & \textbf{1.34} & 1.36 \\
                \hline
            \end{tabular}
        \end{table}
        \begin{table}[!ht]
            \centering
            \caption{RMSE восстановленного с помощью HOSVD SSA с использованием HOOI сигнала, порождённого косинусом. $N=71$}
            \begin{tabular}{r|rrrrrr}
                \hline
                \backslashbox{вид шума}{$I\times L$} & 12$\times$12 & 12$\times$24 & 12$\times$30 & 24$\times$24 & 24$\times$30 & 30$\times$36 \\
                \hline
                белый, $\sigma^2=25$                 & 1.63         & 1.53         & 1.56         & 1.65         & 1.62         & \textbf{1.49} \\
                \hline
                красный, $\varphi=0.5$               & 1.17         & 1.12         & 1.14         & 1.21         & 1.19         & \textbf{1.08} \\
                \hline
                красный, $\varphi=0.9$               & 1.56         & 1.42         & 1.44         & 1.54         & 1.51         & \textbf{1.39} \\
                \hline
            \end{tabular}
        \end{table}
        \note{
            На этом слайде показан результат сравнения SSA и HOSVD SSA с использованием HOOI на примере ряда, порождённого косинусом
            для разных видов шума.
            Во всех случаях SSA показал лучший результат, чем HOSVD SSA.
        }
    \end{frame}

    \begin{frame}{Особый случай}
        Приведём особый пример, в котором HOSVD SSA оказался точнее базового SSA.

        \vspace{0.3cm}
        $x_n = \sin(2\pi n/3 + \pi /2),\, n\in \overline{1:9}$.

        Шум: красный с параметрами $\delta = 0.1,\, \varphi = 0.9$.
        
        \vspace{0.4cm}
        \begin{table}[!ht]
            \centering
            \caption{RMSE восстановленного с помощью различных методов короткого сигнала, порождённого синусом.}
            \begin{tabular}{ccc}
                \hline
                SSA   & HOSVD SSA (HOSVD) & HOSVD SSA (HOOI) \\
                \hline
                0.116 & 0.110             & \textbf{0.095}   \\
                \hline
            \end{tabular}
        \end{table}

        \note{
            Был найден случай временного ряда и шума, для которого метод HOSVD SSA с использованием HOOI оказался
            в среднем точнее, чем SSA.

            Сигнал задан коротким синусом со слайда, на него подействовали красным шумом с параметрами
            $\delta = 0.1,\, \varphi = 0.9$.

            Отклонение считалось аналогично предыдущим примерам по 500 реализациям шума.
            Из таблицы видно, что в случае так заданного ряда, метод HOSVD SSA оказывается точнее стандартного SSA,
            причём самым точным оказался метод с использованием HOOI.

            Причины данного явления на данном этапе остаются неизвестными.
        }
    \end{frame}


    \section{Заключение}\label{sec:conclusion}
    \begin{frame}{Заключение}
        Таким образом:
        \begin{itemize}
            \item Описан и реализован алгоритм HOSVD SSA.
            \item Выведены аналоги важных свойств SSA для метода HOSVD SSA.
            \item Описаны примеры использования метода.
            \item Проведено численное сравнение точности методов HOSVD SSA и SSA, найден особый случай.
        \end{itemize}

        \vspace{0.2cm}
        {\small
        Остаётся для изучения:
            \begin{itemize}
                \item Изучение причин возникновения особого случая.
                \item Определение точной и приближённой разделимости, нахождение метода отделения компонент при отсутствии точной.
                \item Возможность применения других тензорных разложений (CPD).
                \item Подтверждение результатов, утверждающих о преимуществах Tensor SSA над SSA.
            \end{itemize}
        }
        \note{
        \footnotesize
            В результате работы
            \begin{itemize}
                \item был описан и реализован алгоритм HOSVD SSA;
                \item были выведены аналоги важных свойств SSA для метода HOSVD SSA;
                \item Были описаны примеры использования метода;
                \item было проведено численное сравнение точности методов HOSVD SSA и SSA, найден особый случай.
            \end{itemize}

        Для дальнейшего изучения остаётся
        \begin{itemize}
            \item изучение причин возникновения особого случая;
            \item определение точной и приближённой разделимости, нахождение метода отделения компонент при отсутствии точной;
            \item возможность применения других тензорных разложений, в частности CPD;
            \item подтверждение результатов, утверждающих о преимуществах Tensor SSA над SSA;
        \end{itemize}
        }
    \end{frame}


    \section{Список литературы}\label{sec:bib}
    \begin{frame}{Список литературы}
        \begin{thebibliography}{4}
            \bibitem{ssa}
            Golyandina Nina, Nekrutkin Vladimir, Zhigljavsky Anatoly.
            Analysis of time series structure: SSA and related techiques.
            --- Chapman \& Hall/CRC, 2001.

            \bibitem{tssa-hosvd}
            Papy J. M., De Lathauwer L., Van Hu el S.
            Exponential data tting using multilinear algebra: the single-channel
            and multi-channel case~//
            Numerical Linear Algebra with Applications. --- 2005. --- P. 809--826.

            \bibitem{tssa-cpd}
            De Lathauwer Lieven.
            Blind Separation of Exponential Polynomials and the Decomposition
            of a Tensor in Rank-$(L_r, L_r, 1)$ Terms~//
            SIAM Journal on Matrix Analysis and Applications. --- 2011. --- P. 1451--1474.

            \bibitem{hosvd}
            De Lathauwer Lieven, De Moor Bart, Vandewalle Joos.
            A Multilinear Singular Value Decomposition~//
            SIAM Journal on Matrix Analysis and Applications.
            --- 2000. --- P. 1253--1278.

        \end{thebibliography}

        \note{
            На данном слайде представлен список основных источников, используемых в моей работе.
        }
    \end{frame}

\end{document}
